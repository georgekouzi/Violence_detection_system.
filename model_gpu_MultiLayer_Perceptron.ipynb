{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.12'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Disable warnings in Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of metric for classiffication models\n",
    "\n",
    "def metrics_classific(y,predicted,X):\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n",
    "    confusion_matrix = confusion_matrix(y, predicted)\n",
    "    print(confusion_matrix)\n",
    "    print(classification_report(y, predicted))\n",
    "\n",
    "    # Validation ROC-AUC score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    valid_score = roc_auc_score(y, predicted)\n",
    "    print('Validation ROC-AUC score:', valid_score)\n",
    "\n",
    "    # AUC score\n",
    "    from sklearn.metrics import  auc\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y, predicted)\n",
    "    auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print('Validation AUC score:    ', auc)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy_score(y, predicted) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform prob_prediction to predictions\n",
    "def predictor(prob_prediction):\n",
    "    return np.array(([propability[0] < propability[1] for propability in prob_prediction]), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true = pd.read_csv('X_true.csv').values\n",
    "y_true = pd.read_csv('y_true.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10800, 12288), (10800, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_true.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 78\n",
    "test_size = 0.33\n",
    "X_train, X_, y_train, y_ = train_test_split(X_true, y_true, test_size=test_size, random_state=seed)\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X_, y_, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = y_train.shape\n",
    "y_orig = y_train.reshape(shape[0],1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oneHot = OneHotEncoder()\n",
    "oneHot.fit(y_orig) \n",
    "data_y = oneHot.transform(y_orig).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = y_test.shape\n",
    "y_test_orig = y_test.reshape(shape[0],1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oneHot = OneHotEncoder()\n",
    "oneHot.fit(y_test_orig) \n",
    "test_y = oneHot.transform(y_test_orig).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7236, 12288), (7236, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = X_train \n",
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-e08432590937>:22: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_nodes = 5\n",
    "learning_rate = 0.01\n",
    "L2 =0.001 #regulization\n",
    "n_epochs = 9000\n",
    "\n",
    "num_features =data_x.shape[1]\n",
    "num_classes = data_y.shape[1]\n",
    "\n",
    "X_hold = tf.placeholder(tf.float32, [None, num_features]) \n",
    "Y_hold = tf.placeholder(tf.float32, [None,num_classes])\n",
    "\n",
    "#Hidden layer\n",
    "W1 = tf.Variable(tf.truncated_normal([num_features, hidden_layer_nodes], stddev=0.1))\n",
    "W1\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[hidden_layer_nodes]))\n",
    "z1 = tf.add(tf.matmul(X_hold,W1),b1)\n",
    "#a1 = tf.nn.leaky_relu(z1)               #activization function LeakyRelu\n",
    "a1 = tf.nn.relu(z1)                    ##activization function Relu\n",
    "\n",
    "#Dropout Layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "a_drop = tf.nn.dropout(a1, keep_prob)\n",
    "\n",
    "#Output Layer\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden_layer_nodes,num_classes], stddev=0.1)) \n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "z2 = tf.matmul(a_drop,W2) + b2\n",
    "logit = tf.sigmoid(z2) #activization function sigmoid\n",
    "\n",
    "#cost function/cross_entropy\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y_hold, logits=logit) + L2*tf.nn.l2_loss(W1)+ L2*tf.nn.l2_loss(W2))\n",
    "#train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss) # Adam \n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss) #Gradient Descent\n",
    "\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "losses = []\n",
    "aucs = []\n",
    "# Define the accuracy\n",
    "prediction = tf.round(logit)\n",
    "# Bool into float32 type\n",
    "correct = tf.cast(tf.equal(prediction, Y_hold), dtype=tf.float32)\n",
    "# Average\n",
    "accuracy = tf.reduce_mean(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th Epoch Train AUC: 0.4901 Loss: 1.0078\n",
      "100 th Epoch Train AUC: 0.5142 Loss: 0.9342\n",
      "200 th Epoch Train AUC: 0.5188 Loss: 0.9313\n",
      "300 th Epoch Train AUC: 0.5223 Loss: 0.9289\n",
      "400 th Epoch Train AUC: 0.5250 Loss: 0.9271\n",
      "500 th Epoch Train AUC: 0.5266 Loss: 0.9260\n",
      "600 th Epoch Train AUC: 0.5286 Loss: 0.9246\n",
      "700 th Epoch Train AUC: 0.5287 Loss: 0.9241\n",
      "800 th Epoch Train AUC: 0.5313 Loss: 0.9222\n",
      "900 th Epoch Train AUC: 0.5323 Loss: 0.9213\n",
      "1000 th Epoch Train AUC: 0.5326 Loss: 0.9207\n",
      "1100 th Epoch Train AUC: 0.5327 Loss: 0.9201\n",
      "1200 th Epoch Train AUC: 0.5330 Loss: 0.9195\n",
      "1300 th Epoch Train AUC: 0.5334 Loss: 0.9189\n",
      "1400 th Epoch Train AUC: 0.5339 Loss: 0.9181\n",
      "1500 th Epoch Train AUC: 0.5342 Loss: 0.9175\n",
      "1600 th Epoch Train AUC: 0.5348 Loss: 0.9168\n",
      "1700 th Epoch Train AUC: 0.5352 Loss: 0.9162\n",
      "1800 th Epoch Train AUC: 0.5355 Loss: 0.9155\n",
      "1900 th Epoch Train AUC: 0.5361 Loss: 0.9149\n",
      "2000 th Epoch Train AUC: 0.5354 Loss: 0.9146\n",
      "2100 th Epoch Train AUC: 0.5373 Loss: 0.9134\n",
      "2200 th Epoch Train AUC: 0.5377 Loss: 0.9128\n",
      "2300 th Epoch Train AUC: 0.5385 Loss: 0.9120\n",
      "2400 th Epoch Train AUC: 0.5403 Loss: 0.9108\n",
      "2500 th Epoch Train AUC: 0.5394 Loss: 0.9104\n",
      "2600 th Epoch Train AUC: 0.5418 Loss: 0.9092\n",
      "2700 th Epoch Train AUC: 0.5426 Loss: 0.9084\n",
      "2800 th Epoch Train AUC: 0.5434 Loss: 0.9074\n",
      "2900 th Epoch Train AUC: 0.5429 Loss: 0.9072\n",
      "3000 th Epoch Train AUC: 0.5450 Loss: 0.9058\n",
      "3100 th Epoch Train AUC: 0.5453 Loss: 0.9052\n",
      "3200 th Epoch Train AUC: 0.5456 Loss: 0.9046\n",
      "3300 th Epoch Train AUC: 0.5459 Loss: 0.9040\n",
      "3400 th Epoch Train AUC: 0.5466 Loss: 0.9034\n",
      "3500 th Epoch Train AUC: 0.5469 Loss: 0.9027\n",
      "3600 th Epoch Train AUC: 0.5474 Loss: 0.9021\n",
      "3700 th Epoch Train AUC: 0.5478 Loss: 0.9015\n",
      "3800 th Epoch Train AUC: 0.5488 Loss: 0.9005\n",
      "3900 th Epoch Train AUC: 0.5502 Loss: 0.8995\n",
      "4000 th Epoch Train AUC: 0.5508 Loss: 0.8987\n",
      "4100 th Epoch Train AUC: 0.5515 Loss: 0.8980\n",
      "4200 th Epoch Train AUC: 0.5522 Loss: 0.8973\n",
      "4300 th Epoch Train AUC: 0.5529 Loss: 0.8965\n",
      "4400 th Epoch Train AUC: 0.5533 Loss: 0.8959\n",
      "4500 th Epoch Train AUC: 0.5541 Loss: 0.8952\n",
      "4600 th Epoch Train AUC: 0.5543 Loss: 0.8946\n",
      "4700 th Epoch Train AUC: 0.5549 Loss: 0.8941\n",
      "4800 th Epoch Train AUC: 0.5551 Loss: 0.8935\n",
      "4900 th Epoch Train AUC: 0.5555 Loss: 0.8930\n",
      "5000 th Epoch Train AUC: 0.5564 Loss: 0.8922\n",
      "5100 th Epoch Train AUC: 0.5588 Loss: 0.8907\n",
      "5200 th Epoch Train AUC: 0.5601 Loss: 0.8896\n",
      "5300 th Epoch Train AUC: 0.5610 Loss: 0.8888\n",
      "5400 th Epoch Train AUC: 0.5603 Loss: 0.8885\n",
      "5500 th Epoch Train AUC: 0.5635 Loss: 0.8869\n",
      "5600 th Epoch Train AUC: 0.5638 Loss: 0.8862\n",
      "5700 th Epoch Train AUC: 0.5652 Loss: 0.8850\n",
      "5800 th Epoch Train AUC: 0.5664 Loss: 0.8840\n",
      "5900 th Epoch Train AUC: 0.5674 Loss: 0.8833\n",
      "6000 th Epoch Train AUC: 0.5660 Loss: 0.8832\n",
      "6100 th Epoch Train AUC: 0.5699 Loss: 0.8811\n",
      "6200 th Epoch Train AUC: 0.5700 Loss: 0.8808\n",
      "6300 th Epoch Train AUC: 0.5719 Loss: 0.8794\n",
      "6400 th Epoch Train AUC: 0.5735 Loss: 0.8783\n",
      "6500 th Epoch Train AUC: 0.5750 Loss: 0.8772\n",
      "6600 th Epoch Train AUC: 0.5763 Loss: 0.8761\n",
      "6700 th Epoch Train AUC: 0.5781 Loss: 0.8749\n",
      "6800 th Epoch Train AUC: 0.5786 Loss: 0.8742\n",
      "6900 th Epoch Train AUC: 0.5787 Loss: 0.8734\n",
      "7000 th Epoch Train AUC: 0.5806 Loss: 0.8724\n",
      "7100 th Epoch Train AUC: 0.5814 Loss: 0.8717\n",
      "7200 th Epoch Train AUC: 0.5818 Loss: 0.8711\n",
      "7300 th Epoch Train AUC: 0.5821 Loss: 0.8705\n",
      "7400 th Epoch Train AUC: 0.5822 Loss: 0.8700\n",
      "7500 th Epoch Train AUC: 0.5824 Loss: 0.8695\n",
      "7600 th Epoch Train AUC: 0.5827 Loss: 0.8690\n",
      "7700 th Epoch Train AUC: 0.5827 Loss: 0.8686\n",
      "7800 th Epoch Train AUC: 0.5829 Loss: 0.8681\n",
      "7900 th Epoch Train AUC: 0.5829 Loss: 0.8677\n",
      "8000 th Epoch Train AUC: 0.5832 Loss: 0.8672\n",
      "8100 th Epoch Train AUC: 0.5835 Loss: 0.8666\n",
      "8200 th Epoch Train AUC: 0.5839 Loss: 0.8660\n",
      "8300 th Epoch Train AUC: 0.5840 Loss: 0.8656\n",
      "8400 th Epoch Train AUC: 0.5840 Loss: 0.8652\n",
      "8500 th Epoch Train AUC: 0.5841 Loss: 0.8647\n",
      "8600 th Epoch Train AUC: 0.5842 Loss: 0.8643\n",
      "8700 th Epoch Train AUC: 0.5843 Loss: 0.8638\n",
      "8800 th Epoch Train AUC: 0.5843 Loss: 0.8634\n",
      "8900 th Epoch Train AUC: 0.5847 Loss: 0.8629\n",
      "Wall time: 1h 10min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##Initial session\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #save initial weights\n",
    "    Initial_MLP_W1 = sess.run(W1)\n",
    "    Initial_MLP_W2 = sess.run(W2)\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(n_epochs):\n",
    "        _, iloss, y_hat, temp_train_acc = sess.run([train_step, loss, prediction, accuracy], {X_hold:data_x, Y_hold:data_y,keep_prob : 1.0})\n",
    "        temp_test_acc = sess.run(accuracy, feed_dict={X_hold:X_test, Y_hold:test_y,keep_prob : 1.0}) \n",
    "        if i%100==0:\n",
    "            train_acc.append(temp_train_acc)\n",
    "            test_acc.append(temp_test_acc)\n",
    "            losses.append(iloss)\n",
    "            aucs.append(roc_auc_score(data_y, y_hat))\n",
    "        if i%100==0:\n",
    "            print('%i th Epoch Train AUC: %.4f Loss: %.4f' % (i, roc_auc_score(data_y, y_hat), iloss))\n",
    "    \n",
    "    multi_prob_predictions = sess.run(z2, feed_dict={X_hold:X_test, keep_prob : 1.0})\n",
    "    W1_matrix = sess.run(W1)\n",
    "    W2_matrix = sess.run(W2)\n",
    "    b1_vector = sess.run(b1)\n",
    "    b2_vector = sess.run(b2)\n",
    "    saver.save(sess, 'MLP_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 301  767]\n",
      " [ 213 1106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.28      0.38      1068\n",
      "         1.0       0.59      0.84      0.69      1319\n",
      "\n",
      "    accuracy                           0.59      2387\n",
      "   macro avg       0.59      0.56      0.54      2387\n",
      "weighted avg       0.59      0.59      0.55      2387\n",
      "\n",
      "Validation ROC-AUC score: 0.5601746158848067\n",
      "Validation AUC score:     0.5601746158848067\n",
      "Accuracy: 58.94%\n"
     ]
    }
   ],
   "source": [
    "tensor_predictions = predictor(multi_prob_predictions)\n",
    "metrics_classific(y_test,tensor_predictions, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkUklEQVR4nO3deZRcZ33m8e9Te69qy2prs7FMkB0YCDYomB0nJmATEid/JMGBYcniQwYmMJAZDEMmIZCFmSQDGUgYhzVh8WSAExyOwxIGcEggcTvYgG3sCK+KJLtluaVWd9f+mz/ure7qVm+SWyr17edzzj1Vd6n3vvWq9dx73/dWlSICMzNb/3K9roCZma0NB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6LYhSLpP0gt7XQ+zU8mBbmaWEQ5027AklSW9R9L+dHqPpHK6boukz0uakHRY0t9LyqXr3iLp3yRNSrpL0uW9fSdmiUKvK2DWQ/8VeCZwMRDA54C3A78JvBnYB4ym2z4TCEkXAa8HfjQi9kvaBeRPb7XNFuczdNvIXg78TkQ8HBHjwDuAf5+uawDbgfMjohERfx/JFx+1gDLwJEnFiLgvIn7Qk9qbLeBAt41sB3B/1/z96TKA/wHsBb4k6R5J1wJExF7gjcBvAw9Lul7SDszOAA5028j2A+d3zT8uXUZETEbEmyPi8cBPAW/q9JVHxCcj4rnpawN49+mtttniHOi2kRQlVToT8Cng7ZJGJW0B/hvwcQBJL5X0BEkCjpJ0tbQkXSTpx9PB0yowk64z6zkHum0kN5IEcGeqAGPAd4DvAv8CvCvddjfwd8Ax4JvAn0bE10j6z/8AOAQcBM4B3nba3oHZMuQfuDAzywafoZuZZYQD3cwsIxzoZmYZ4UA3M8uInn30f8uWLbFr165e7d7MbF265ZZbDkXE6GLrehbou3btYmxsrFe7NzNblyTdv9Q6d7mYmWXEioEu6cOSHpb0vSXWS9KfSNor6TuSnrb21Zyv1fa982ZmC63mDP2jwBXLrL+S5FN1u4FrgD977NVa2he+d5BLfudLPHS0eip3Y2a27qwY6BFxE3B4mU2uAv4iEt8CRiRtX6sKLvS4zf0crTa56e7xU7ULM7N1aS360HcCD3bN70uXHUfSNZLGJI2Nj59cID9x+xCjQ2W+7kA3M5tnLQJdiyxbtJM7Iq6LiD0RsWd0dNG7blbemcTzd4/yjb2H3JduZtZlLQJ9H3Be1/y5pN8pfaq84KJRJqYbfGffxKncjZnZurIWgX4D8Mr0bpdnAkci4sAalLuk5z1hCxLcdPehU7kbM7N1ZTW3LX6K5PugL5K0T9IvS3qtpNemm9wI3EPyc11/DvyHU1bb1FkDJX7k3BG+fvfDp3pXZmbrxoqfFI2Iq1dYH8Dr1qxGq/SC3Vt431f3cmS6wab+4unevZnZGWfdflL0BReN0g74xl53u5iZwToO9KeeO8JwpeBuFzOz1LoN9EI+x3N3b+Gmuw/hn9EzM1vHgQ7wggtHOXi0yt0PHet1VczMeq5nX5+7Fp5/YfLhpN+78U4uu2iUXVsGOH9zPztG+qgU8z2unZnZ6bWuA337pj6uungHf3fHQ8d9FcDmgRLbN1U4Z6jM2YNlzh4scVZ/iaFKgaFKkeFKgeG+IsOVIpv6ivSX8hTzOYp5IS324VczszPbug50gPe+7BIigkPH6tz3yBQPPDLNgSMz7D9SZf/EDIeO1bnr4CSHjtWpt9qrKrNcyLFlsMzoUJktg2WGKwX6Snn6S3n6innKxTzlQo5yIUepM+Xzs/PlQm7eNp3nfcU8lWKefM4HDDNbe+s+0CH5fpfRoSSAf3TX5kW3iQim6y0mq02O1RocmWlytNrg6EyDIzMNqo0WjVZQb7aZabQ4dKzG+GSNfY9OM1ltMtNoMV1vUm2s7qCwnGJelPLzQ7+Shn2lmKNU6DoYFPKUi13PCznKxRylfI5CTuRzIpcT/aU8g+UiQ5UCg+UCleLcazsHkmJ+XQ+ZmNkKMhHoqyGJgXKBgXIBqJx0ORFBvdWm1mxTa7Spt9rUm8lUa7bSx7nn1UabaqNFrZk8VhttqrPbtag1ku1nGq1ku0abIzMNao3ustrUGi1q6b5OViEN/qFKEvwD5QLFvCjkchTyybrhSpHhviJD5cLsAaZSzNNfKjBQzjNQLtBXzJOTyOWSMgfLSbdVpZhzd5VZD22YQF8rktIz5fxjOS6ctHZ77oDSbgetCFrtztVHI70Cac4eBKrp40y9xUyjxVStyWStybFqk6l6k0YzmG42abaDBw83OVptcnSmQe0kDhylQo7BciG9+sjNeyx1XWGUlrnyKBeO76oqdV2tVIo5BkoF+sv55LGU90HELOVAX2dyOVHJ5U/5XTz1ZnIl0blqmKo3maolB4Rqo0U7kquVZjuYrDaZmKlzZLrBVL05d2XRdQVTa7aYmK5TaybLOlcmnauU1Y5vLCTBQCnpZuor5We7rzqPfV1XGZVichCpFPLputzssnIhP3sA6n79woNSMl7iKxE7MznQbVGd8BqunJ7vyZm98ljQJVVtdB8AkvnpepPpejKmcazW4lg6LjLT6HRrJQeJR6frHOh0c6XLq83H1m3VsTDgu59Xijn6SnkqhTx9pTwj/UVG+kqM9Cd3VSVdf3PdV32ldIwjHRPJ5zR7ADI7EQ50OyN0X3ls4tQeRNrtSK8+5sY36ukYR73Vnj0gVLvHRNJ1s+MlrTaNZlBvtWaXzV2NtJmptzgy02C61mJipsHEdJ0T/T2WgVKezYMlNveX5q4wCjkGygWGKgWGK0UGKwUGSnNjHJ2rkr70NlwJhMjn4Kz+5NbdnO+yyiwHum04yV1BBfpLp2+f7bRrarLWYKrW4lityXS9OTu20bnLqh1BsxXMNFo8cqzO4akaj04nd2FNpIPlU/Umk+lYx4keJAo5cc5QmeG+IvmcKOREMZ9juC8Z2N7UN3enVOfAMVhOp0qBoXKRgXKewUohGUeyM4oD3ew0yOXEpv7imn7Vc0SkA91J99NUbe7gUE3vkgogAloRHD5W46HJGg8drXKs2qTVTsZA6s02D09WufuhSY7MNDhWa7Kar0fqdMkNV5Lgn7sNNxm36Fwp9BWT7qXk1trCbBdTpZin0jVI3hn87u7G8of9TowD3WydkjpXGgWgvGbldj6zMVVL7nqaqiV3Tk1WG+mYRSOdT++KSu+uqjWSK49HjtWTLq16i+lGi+l66zGPWxRymh2nKOa7A19p6C98vsy6gijm0nK67qKafZzdLkcxJwpdry+kt/mWOs/Tz5R01hVzuZ52aTnQzWye7s9snDO8NmU2Wm2may2Opd1MydhFOujdudtpwVhEvdmevYKot9o0W93rg0Y632i1abSDRvqaqXqLRmd5q02jFTTbyWNnWb3ZPuHuqtXqdGMVZg8i6UGg6wD0c08/l1c/54K13/eal2hmtkAxn2NTf+6M+nWxZmvhBwPn5put5K6rRit53mi3aaQHmNmDxAoHjM7yTlnNrvXJBxzXngPdzDakQj5HIZ87rYPjp5q/3MPMLCMc6GZmGeFANzPLCAe6mVlGONDNzDJiVYEu6QpJd0naK+naRdZvkvQ3km6TdLuk16x9Vc3MbDkrBrqkPPB+4ErgScDVkp60YLPXAXdExFOBy4A/kpShm4HMzM58qzlDfwawNyLuiYg6cD1w1YJtAhhS8oULg8BhoLmmNTUzs2WtJtB3Ag92ze9Ll3V7H/BEYD/wXeANEXHclzdIukbSmKSx8fHxk6yymZktZjWBvtg3zSz8FoQXA7cCO4CLgfdJOu5bICLiuojYExF7RkdHT7CqZma2nNUE+j7gvK75c0nOxLu9BvhsJPYC9wI/vDZVNDOz1VhNoN8M7JZ0QTrQ+TLghgXbPABcDiBpK3ARcM9aVtTMzJa34pdzRURT0uuBLwJ54MMRcbuk16brPwC8E/iopO+SdNG8JSIOncJ6m5nZAqv6tsWIuBG4ccGyD3Q93w+8aG2rZmZmJ8KfFDUzywgHuplZRjjQzcwywoFuZpYRDnQzs4xwoJuZZYQD3cwsIxzoZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwjHOhmZhnhQDczy4hVBbqkKyTdJWmvpGuX2OYySbdKul3S19e2mmZmtpLCShtIygPvB34C2AfcLOmGiLija5sR4E+BKyLiAUnnnKL6mpnZElZzhv4MYG9E3BMRdeB64KoF2/wi8NmIeAAgIh5e22qamdlKVhPoO4EHu+b3pcu6XQicJelrkm6R9MrFCpJ0jaQxSWPj4+MnV2MzM1vUagJdiyyLBfMF4OnATwIvBn5T0oXHvSjiuojYExF7RkdHT7iyZma2tBX70EnOyM/rmj8X2L/INociYgqYknQT8FTg7jWppZmZrWg1Z+g3A7slXSCpBLwMuGHBNp8DniepIKkfuBS4c22ramZmy1nxDD0impJeD3wRyAMfjojbJb02Xf+BiLhT0heA7wBt4IMR8b1TWXEzM5tPEQu7w0+PPXv2xNjYWE/2bWa2Xkm6JSL2LLbOnxQ1M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwjHOhmZhnhQDczywgHuplZRjjQzcwywoFuZpYRPfuRaEnjwP0n+fItwKE1rE4WuE3mc3scz20y33ptj/MjYnSxFT0L9MdC0thSv3q9UblN5nN7HM9tMl8W28NdLmZmGeFANzPLiPUa6Nf1ugJnILfJfG6P47lN5stce6zLPnQ780j6W+D6iPhYj+vx28ATIuIVvayHWS+s1zN0WwOSjnVNbUkzXfMvP5GyIuLKXof5ciS9vOu9zaTvd/b9n0R5uySFpMIqtn11uu3Pn1ztzVbHgb6BRcRgZwIeAH6qa9knOtutJrTOdBHxia73eiWwf8H7P5VeBRxOH0+bLPy72YlxoNtxJF0maZ+kt0g6CHxE0lmSPi9pXNKj6fNzu17zNUm/kj5/taRvSPrDdNt7JV25zP6ulfQDSZOS7pD0s13rli1L0gWSvp6+9ssk9xaf6PvdIekz6Xu7V9Kvd617hqQxSUclPSTpj9NVN6WPE+lZ/rOWKPt84AXANcCLJW3tWpeX9Lau936LpPPSdf9O0pclHU73+7Z0+UclvaurjMsk7euavy/9d/sOMCWpsFz7pq/5VUl3dq1/mqT/LOkzC7b7X5Lec6Lta6ePA92Wsg3YDJxPEkY54CPp/OOAGeB9y7z+UuAukoD978CHJGmJbX8APA/YBLwD+Lik7ass65PALem6d3KCZ8GScsDfALcBO4HLgTdKenG6yXuB90bEMPBDwF+ly5+fPo6kZ/nfXGIXrwTGIuIzwJ1Ad1fWm4CrgZcAw8AvAdOShoC/A74A7ACeAHzlBN7W1cBPpnVrskz7Svo54LfTeg4DPw08AnwcuELSSLpdAfgF4C9PoB52ukWEJ08A9wEvTJ9fBtSByjLbXww82jX/NeBX0uevBvZ2resHAti2yrrcCly1UlkkB5YmMNC1/pPAx1co/zJgX/r8UuCBBevfCnwkfX4TSQhuWbDNrrQehRX29a/AG7vKva1r3V2d97ngNVcD316ivI8C71rsvXT9O/7SCbTvF4E3LLHd3wK/mj5/KXBHr/9OPS0/+QzdljIeEdXOjKR+Sf9b0v2SjpIE3Yik/BKvP9h5EhHT6dNF+6olvVLSrZImJE0AT2Z+18lSZe0gOahMdW17ol8ncT6wo7PvdP9vAzpdI78MXAh8X9LNkl662oIlPQe4ALg+XfRJ4CmSLk7nzyM5e15oqeWr9eCCeizXvsvt62NA526hV+Cz8zOeA92WsvB+1jcDFwGXRtL90OlyWKobZVXSPuY/B14PnB0RI8D3VlnuAeAsSQNdyx53glV4ELg3Ika6pqGIeAlARPxrRFwNnAO8G/h0ur/V3O/7KpL3cWs6FvFP6fJXdu37h5ao02LLAaZIrlI6ti2yzWzdVtG+y+3rr4EfkfRkkjP0TyyxnZ0hHOi2WkMk/eYTkjYDv7VG5XbCcRxA0mtIziBXFBH3A2PAOySVJD0X+KkT3P8/A0fTgcS+dKDyyZJ+NK3PKySNRkQbmEhf00rr2wYev1ihkirAz5OMP1zcNf1H4OVpn/QHgXdK2q3Ej0g6G/g8sE3SGyWVJQ1JujQt+lbgJZI2S9oGvHGF97dS+34Q+A1JT0/r8IT0IEB6hfZpkiuLf46IB1bYl/WYA91W6z1AH8m3032LZMDuMYuIO4A/Ar4JPAQ8BfiHEyjiF0n6wQ+THGT+4gT33yI5CFwM3Evy/j5IMoAIcAVwu5J71d8LvCwiqmnXz+8C/5B2ZTxzQdE/Q3IA/IuIONiZgA8B+bTcPyYZZP0ScDRd1xcRk8BPpPU6SNIP/2NpuX9JMoB7X/q6/7PC+1u2fSPi/6bv45PAJMlZ+eauIj6WvsbdLeuAPylqZkuS9Djg+yQD2kd7XR9bns/QzWxR6S2dbyL5SgeH+TrgT5KZ2XHSgd+HSO4auqLH1bFVcpeLmVlGuMvFzCwjetblsmXLlti1a1evdm9mti7dcssth2KJ3xTtWaDv2rWLsbGxXu3ezGxdkrTkp6Hd5WJmlhErBrqkD0t6WNL3llgvSX8iaa+k70h62tpX08zMVrKaM/SPsvxtS1cCu9PpGuDPHnu1zMzsRK0Y6BFxE8nHqpdyFcnHmyMivkXyDXzbl9nezMxOgbXoQ9/J/K/r3JcuO46ka5T8+svY+Pj4GuzazMw61iLQF/ua00U/rRQR10XEnojYMzq66F03ZmZ2ktYi0PeRfEl+x7nA/jUo18zMTsBaBPoNwCvTu12eCRyJiANrUK6ZmZ2AFT9YJOlTJL9buCX9dfHfAooAEfEB4EaSH7ndC0wDrzlVlTUzs6WtGOjpz28ttz6A161ZjczM7KT4k6JmZhnhQDczywgHuplZRjjQzcwywoFuZpYRDnQzs4xwoJuZZYQD3cwsIxzoZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwjVhXokq6QdJekvZKuXWT9Jkl/I+k2SbdLes3aV9XMzJazYqBLygPvB64EngRcLelJCzZ7HXBHRDwVuAz4I0mlNa6rmZktYzVn6M8A9kbEPRFRB64HrlqwTQBDkgQMAoeB5prW1MzMlrWaQN8JPNg1vy9d1u19wBOB/cB3gTdERHthQZKukTQmaWx8fPwkq2xmZotZTaBrkWWxYP7FwK3ADuBi4H2Sho97UcR1EbEnIvaMjo6eYFXNzGw5qwn0fcB5XfPnkpyJd3sN8NlI7AXuBX54bapoZmarsZpAvxnYLemCdKDzZcANC7Z5ALgcQNJW4CLgnrWsqJmZLa+w0gYR0ZT0euCLQB74cETcLum16foPAO8EPirpuyRdNG+JiEOnsN5mZrbAioEOEBE3AjcuWPaBruf7gRetbdXMzOxE+JOiZmYZ4UA3M8sIB7qZWUY40M3MMsKBbmaWEQ50M7OMcKCbmWWEA93MLCMc6GZmGeFANzPLCAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwjHOhmZhnhQDczywgHuplZRjjQzcwywoFuZpYRDnQzs4xwoJuZZYQD3cwsI1YV6JKukHSXpL2Srl1im8sk3SrpdklfX9tqmpnZSgorbSApD7wf+AlgH3CzpBsi4o6ubUaAPwWuiIgHJJ1ziuprZmZLWM0Z+jOAvRFxT0TUgeuBqxZs84vAZyPiAYCIeHhtq2lmZitZTaDvBB7smt+XLut2IXCWpK9JukXSKxcrSNI1ksYkjY2Pj59cjc3MbFErdrkAWmRZLFLO04HLgT7gm5K+FRF3z3tRxHXAdQB79uxZWIaZGQAR0G7Pn7qXtVrzp4j5U2f7iPlldrZvNuemRmPusTO1WnOvWViv7nIX1nPhPrtf19lPswmXXALPfvbat9tqAn0fcF7X/LnA/kW2ORQRU8CUpJuApwJ3Y2aZEgHT03D4MDz8MIyPw6FDUK1CvZ5M7XayrZQE2MGDcOBA8nj0aPL66WmYmZkfqs1mEqad12fVW97Su0C/Gdgt6QLg34CXkfSZd/sc8D5JBaAEXAr8z7WsqJmtjVYLJifnznQbjSSQu8O5Mz3ySBLcjz6aTBMTcORIErwnoq8Ptm+Hbdtg61bo74eBAahUoFiEQmH+lM9DLjf3KCWPnef5/PxJmpu6t9eC/oV8fq78QmH+vovFualTJhxfRve+OmV29rVwXbdO2YVC8t5PhRUDPSKakl4PfBHIAx+OiNslvTZd/4GIuFPSF4DvAG3ggxHxvVNTZbONZWYGarW5M9ipqeQs98iRuakTtJOTcOxYMkXA6GgSoJs2wfe/D2Nj8O1vJ2fHy5Fg8+a5acsW2L0bzjorKWtkJHl+zjnJPrZsSUK7VEqmfH6u+yGfh8HBxUPuVIkIms0mjUaDdrtNq9Wi3W6Ty+XI5XLk83kKhQLFYhF1VazdbtNoNGg2m7OvAygWi7OTHsMb6ZSflFF6rG/zOIrFOnxOgz179sTY2FhP9m12Os3MwL59yXToUBK+nQCemkqm6Wkol2FoKJmOHYM77kimfftWv6++viQ8O2eA4+NJ+ZCcFV98MezZA7t2QS4XSG2gTqn0MHCQVushcrkjwDQzM1McOXKEAwcOsH//fg4cOMD09DSNRoN6vU673Safz5PL5SgWi5x11lmMjo4yOjpKo9Fg//797N+/n0OHDrFcznTKyOfzlMtlyuUylUoFSVSrVWq1GrVabXabXC43G4z1ep1ms0mr1ZoN7U4gr1Yn3DvhvxJJ5PN58vk8kuYFfPcBA5itV6vVmlf+tddey+///u+vuo4L9n9LROxZbN1qulzM1pWIpB+3Wp0/zczMPXamajXpcqjXk8fu9dXqXJ9us5lsU6slU6Mxf3Cue4CtVktePz2dnDEfPrx4PXO5JHgHBpKwrdWS7ScnoVJpc+GFh7nkkod40YvGKRRqJHcNN5CmkY4RMYk0TV9fjv7+HP39edrtBtVqlWq1ytTUFIcPH2Z8/DCHDh1mZuYoe/dO8u1vT1KtVpcN2Q5JbN26lR07drB9+3YGBgZmz1Q7wdoJq8OHD7N//35uu+028vk8O3fu5ClPeQqjo6OzAXf8v1XMltFqtajX67P1b7fb9PX1UalUKJVKRMTsdp2DSKlUolAozAZsZ/nCdZ2g7S6jcwbfOQB0n4V3vw6g2WxSr9dpNBrzDh7dB4CImFe+pNlwz+fz8+r1rGc964T/rlfDgW5rZnp6rn914SBX57E7/Gq1ubDt3F3QeW1ncK07bDshPTU1163QOdudmEj2X60m5T5W+TyUy20KhQaFQoNcrkGplKNcLlKplCgWQaohVZFq5HJVcrkqUpVi8Qil0jhDQ+Ns3XqYcvkY5fI0hcJ0uk0DqUGzWWViYoKJiQmOHj1KvV4nn28xPNxmamqK225rctttJ173XC5HX18f/f39nH322WzevJldu3YyPPxEhoaGGBoaolKpzAua0dFRtm3bxtatWxkZGWFgYID+/n4GBgYoFBwT64X/pTaIRiMJvKNHk8vw8fEkBPv65i7zJyfhgQeS6cCBuTsRuqepqSSU+/qSs8pSKSlr375k0OxUSQaxWvT11ejvb9DX16C/v8bAwCTbt0+ya9ck+fxR2u0JWq0Jms0jtFqTNJuTNBrHyOXaswNo7XaNanUynaZot5tEtGm3WzQaNaanp5ienmZ6eg2ODEC5XKa/v5/+/n4qlcrsmVqlUmFkZITzzjuP4eFhSqXSbMj29/ezdetWtm3bxujo6LzX9ff3zwZzX1/fvLPcztmlbUz+lz8B9frxt1ktvFe2+4y0+77WzqV452yz++y1+1K+s75zRtp9Kd8pozNAVqkEhcJRWq39TE2JRx8d4pFHhpiYKFGrTVKvJ2FWq7W7bgNrAQ2gDlSBgyR3oe4HmsAA0E9/fx+lktJR+SCfPwocpt0+TKNxiGp1nFrtEI3GYXK5EuXyEFu2DFEsFmm3G+nUolgsUSxWKJXK6SV6C0jCs91u0GzWabeb6Z0LnX5JZgO21WoyMzPD1NRU2peaHIhWoxN8g4OD8y75i8UiQ0NDbNs2zODgDgqFwrw+3M7ZaV9fH6VSafbSvdM/22g0iAgqlQqVSoVyuUxfX99s3+/w8DCjo6Ns2bKFs88+2wFrp82G+0uLSM4yx8fn7o09cCBZ1vmQwMxMcpZ6//3J46OPJpf3jcZKpbdIgrLRNXXmW11Td99lANPA5LxJmiSXO0Yu1ySXa5HLtZAmgXEixmm1HqbROEDECrcrrFJ//zDFYolabYpqdWb2jLyjUCiwefNmNm/ezNlnn83o6BMYHX0WmzdvplarMTk5yeTk5Ly+yHw+P69PNCLmDYCVSqV5Z5SdfsmF23Uu/Ree4ZbLZQYHBxkeHmZoaIhNmzaxadMmRkZGGBoacpDahpPJv/iJieTugDvvhL17g7vuOsrevQc5ePAIExMNGo06SdAeSaeJdL6jyeDgEfr7j1AuH2HTphqbN7fJ5VpENGg0pmg0pmk0pqnXp6jXp6nXp2m1TvDm3GUk41V58vnibLANDAzM3kUwOrqHHTt2sHPnTrZv3w4wG6r1ep2hoSGGh4ePOzvtHkwql8ts27ZtdrCro91uU1vQEd2568DMzlzrPtAnJtp8/vMH+NrX7uOWW+7nBz+4j8nJe4B7gHuBA8DJ9IUOUixuYmhoE+Vyed4I+sDAJvr7t8+eOS529tgJze5R8+7brrp194l2T+VyuSch2hlUM7P1ZV0Heq3WZtu251CrfWve8sHBrZx77uO58MJns3v3TrZvTwaXRkZGZkO2VCoxPDzMyMgImzZtolKpzL6++z5SM7P1Yl0H+jvf+WVqtW9x+eVv4td+7YU88Ynnc/7558/rPjAz2yjWdaBfd9115HJbuOGG36O/v9zr6piZ9dS6/U3Rb3zjAOPjN/DsZ7/aYW5mxjoO9Le+9aNAkz/4g1/tdVXMzM4I6zLQp6fb/OM//jmjoz/Gc55zYa+rY2Z2RliXgf6Od3yFdvterrnmml5XxczsjLEuA/1DH7qOXO5s3v72n+11VczMzhjrLtC/+tWHeOSRv+Z5z3s1lYoHQ83MOtZdoH/hC18Gmrz73e5uMTPrtu4C/d3vfgX33Xc/l17qwVAzs27rLtABzj//cb2ugpnZGWddBrqZmR3PgW5mlhFazQ/FnpIdS+PA/Sf58i3AoTWsTha4TeZzexzPbTLfem2P8yNidLEVPQv0x0LSWETs6XU9ziRuk/ncHsdzm8yXxfZwl4uZWUY40M3MMmK9Bvp1va7AGchtMp/b43huk/ky1x7rsg/dzMyOt17P0M3MbAEHuplZRqy7QJd0haS7JO2VdG2v63O6STpP0lcl3SnpdklvSJdvlvRlSf+aPp7V67qeTpLykr4t6fPp/EZvjxFJn5b0/fRv5VkbuU0k/af0/8v3JH1KUiWL7bGuAl1SHng/cCXwJOBqSU/qba1Ouybw5oh4IvBM4HVpG1wLfCUidgNfSec3kjcAd3bNb/T2eC/whYj4YeCpJG2zIdtE0k7g14E9EfFkIA+8jAy2x7oKdOAZwN6IuCci6sD1wFU9rtNpFREHIuJf0ueTJP9Rd5K0w8fSzT4G/ExPKtgDks4FfhL4YNfijdwew8DzgQ8BREQ9IibYwG0CFIA+SQWgH9hPBttjvQX6TuDBrvl96bINSdIu4BLgn4CtEXEAktAHzulh1U639wD/BWh3LdvI7fF4YBz4SNoN9UFJA2zQNomIfwP+EHgAOAAciYgvkcH2WG+BrkWWbcj7LiUNAp8B3hgRR3tdn16R9FLg4Yi4pdd1OYMUgKcBfxYRlwBTZKA74WSlfeNXARcAO4ABSa/oba1OjfUW6PuA87rmzyW5dNpQJBVJwvwTEfHZdPFDkran67cDD/eqfqfZc4CflnQfSRfcj0v6OBu3PSD5f7IvIv4pnf80ScBv1DZ5IXBvRIxHRAP4LPBsMtge6y3QbwZ2S7pAUolkYOOGHtfptJIkkr7ROyPij7tW3QC8Kn3+KuBzp7tuvRARb42IcyNiF8nfw/+LiFewQdsDICIOAg9KuihddDlwBxu3TR4AnimpP/3/cznJ2FPm2mPdfVJU0ktI+kzzwIcj4nd7W6PTS9Jzgb8Hvstcn/HbSPrR/wp4HMkf8M9FxOGeVLJHJF0G/EZEvFTS2Wzg9pB0MckgcQm4B3gNyQnchmwTSe8AfoHkLrFvA78CDJKx9lh3gW5mZotbb10uZma2BAe6mVlGONDNzDLCgW5mlhEOdDOzjHCgm5llhAPdzCwj/j+fAqKBCbgvLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1),(ax2)) = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True)\n",
    "        \n",
    "ax1.plot(range(n_epochs//100), losses)\n",
    "ax1.title.set_text('Loss') \n",
    "        \n",
    "# accuracy\n",
    "ax2.plot(train_acc, 'b-', label='train accuracy')\n",
    "ax2.plot(test_acc, 'k-', label='test accuracy')\n",
    "ax2.title.set_text('Train and Test Accuracy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "from numpy import loadtxt\n",
    "np.savetxt('Initial_MLP_W1.csv', Initial_MLP_W1, delimiter=',')\n",
    "np.savetxt('Initial_MLP_W2.csv', Initial_MLP_W2, delimiter=',')\n",
    "\n",
    "np.savetxt('W1_matrix.csv', W1_matrix, delimiter=',')\n",
    "np.savetxt('W2_matrix.csv', W2_matrix, delimiter=',')\n",
    "\n",
    "np.savetxt('b1_vector.csv', b1_vector, delimiter=',')\n",
    "np.savetxt('b2_vector.csv', b2_vector, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restored session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MLP_0.meta'\n",
    "num_features =data_x.shape[1]\n",
    "num_classes = data_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "L2 =0.001 #regulization\n",
    "n_epochs = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initial_MLP_W1 = pd.read_csv('Initial_MLP_W1.csv',header=None).values\n",
    "Initial_MLP_W2 = pd.read_csv('Initial_MLP_W2.csv',header=None).values\n",
    "W1 = pd.read_csv('W1_matrix.csv',header=None).values\n",
    "W2 = pd.read_csv('W2_matrix.csv',header=None).values\n",
    "b1 = pd.read_csv('b1_vector.csv',header=None).values\n",
    "b2 = pd.read_csv('b2_vector.csv',header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./MLP_0\n",
      "0 th Epoch Train AUC: 0.5849 Loss: 0.8624\n",
      "100 th Epoch Train AUC: 0.5850 Loss: 0.8620\n",
      "200 th Epoch Train AUC: 0.5852 Loss: 0.8615\n",
      "300 th Epoch Train AUC: 0.5853 Loss: 0.8611\n",
      "400 th Epoch Train AUC: 0.5853 Loss: 0.8606\n",
      "500 th Epoch Train AUC: 0.5854 Loss: 0.8602\n",
      "600 th Epoch Train AUC: 0.5854 Loss: 0.8598\n",
      "700 th Epoch Train AUC: 0.5854 Loss: 0.8594\n",
      "800 th Epoch Train AUC: 0.5855 Loss: 0.8590\n",
      "900 th Epoch Train AUC: 0.5856 Loss: 0.8585\n",
      "1000 th Epoch Train AUC: 0.5856 Loss: 0.8581\n",
      "1100 th Epoch Train AUC: 0.5856 Loss: 0.8577\n",
      "1200 th Epoch Train AUC: 0.5856 Loss: 0.8574\n",
      "1300 th Epoch Train AUC: 0.5856 Loss: 0.8570\n",
      "1400 th Epoch Train AUC: 0.5856 Loss: 0.8566\n",
      "1500 th Epoch Train AUC: 0.5858 Loss: 0.8561\n",
      "1600 th Epoch Train AUC: 0.5859 Loss: 0.8557\n",
      "1700 th Epoch Train AUC: 0.5860 Loss: 0.8552\n",
      "1800 th Epoch Train AUC: 0.5861 Loss: 0.8548\n",
      "1900 th Epoch Train AUC: 0.5861 Loss: 0.8544\n",
      "2000 th Epoch Train AUC: 0.5863 Loss: 0.8540\n",
      "2100 th Epoch Train AUC: 0.5863 Loss: 0.8536\n",
      "2200 th Epoch Train AUC: 0.5864 Loss: 0.8532\n",
      "2300 th Epoch Train AUC: 0.5864 Loss: 0.8528\n",
      "2400 th Epoch Train AUC: 0.5864 Loss: 0.8524\n",
      "2500 th Epoch Train AUC: 0.5864 Loss: 0.8520\n",
      "2600 th Epoch Train AUC: 0.5865 Loss: 0.8516\n",
      "2700 th Epoch Train AUC: 0.5865 Loss: 0.8512\n",
      "2800 th Epoch Train AUC: 0.5866 Loss: 0.8508\n",
      "2900 th Epoch Train AUC: 0.5867 Loss: 0.8504\n",
      "3000 th Epoch Train AUC: 0.5867 Loss: 0.8500\n",
      "3100 th Epoch Train AUC: 0.5867 Loss: 0.8496\n",
      "3200 th Epoch Train AUC: 0.5868 Loss: 0.8492\n",
      "3300 th Epoch Train AUC: 0.5870 Loss: 0.8488\n",
      "3400 th Epoch Train AUC: 0.5870 Loss: 0.8483\n",
      "3500 th Epoch Train AUC: 0.5870 Loss: 0.8479\n",
      "3600 th Epoch Train AUC: 0.5872 Loss: 0.8475\n",
      "3700 th Epoch Train AUC: 0.5874 Loss: 0.8471\n",
      "3800 th Epoch Train AUC: 0.5875 Loss: 0.8466\n",
      "3900 th Epoch Train AUC: 0.5876 Loss: 0.8462\n",
      "4000 th Epoch Train AUC: 0.5877 Loss: 0.8458\n",
      "4100 th Epoch Train AUC: 0.5877 Loss: 0.8454\n",
      "4200 th Epoch Train AUC: 0.5877 Loss: 0.8450\n",
      "4300 th Epoch Train AUC: 0.5879 Loss: 0.8446\n",
      "4400 th Epoch Train AUC: 0.5879 Loss: 0.8442\n",
      "4500 th Epoch Train AUC: 0.5881 Loss: 0.8438\n",
      "4600 th Epoch Train AUC: 0.5881 Loss: 0.8434\n",
      "4700 th Epoch Train AUC: 0.5882 Loss: 0.8430\n",
      "4800 th Epoch Train AUC: 0.5885 Loss: 0.8426\n",
      "4900 th Epoch Train AUC: 0.5886 Loss: 0.8422\n",
      "5000 th Epoch Train AUC: 0.5886 Loss: 0.8418\n",
      "5100 th Epoch Train AUC: 0.5889 Loss: 0.8413\n",
      "5200 th Epoch Train AUC: 0.5890 Loss: 0.8409\n",
      "5300 th Epoch Train AUC: 0.5891 Loss: 0.8405\n",
      "5400 th Epoch Train AUC: 0.5893 Loss: 0.8401\n",
      "5500 th Epoch Train AUC: 0.5893 Loss: 0.8397\n",
      "5600 th Epoch Train AUC: 0.5895 Loss: 0.8393\n",
      "5700 th Epoch Train AUC: 0.5897 Loss: 0.8388\n",
      "5800 th Epoch Train AUC: 0.5898 Loss: 0.8384\n",
      "5900 th Epoch Train AUC: 0.5899 Loss: 0.8380\n",
      "6000 th Epoch Train AUC: 0.5899 Loss: 0.8377\n",
      "6100 th Epoch Train AUC: 0.5899 Loss: 0.8373\n",
      "6200 th Epoch Train AUC: 0.5900 Loss: 0.8369\n",
      "6300 th Epoch Train AUC: 0.5900 Loss: 0.8366\n",
      "6400 th Epoch Train AUC: 0.5901 Loss: 0.8362\n",
      "6500 th Epoch Train AUC: 0.5901 Loss: 0.8358\n",
      "6600 th Epoch Train AUC: 0.5901 Loss: 0.8355\n",
      "6700 th Epoch Train AUC: 0.5903 Loss: 0.8350\n",
      "6800 th Epoch Train AUC: 0.5903 Loss: 0.8347\n",
      "6900 th Epoch Train AUC: 0.5904 Loss: 0.8343\n",
      "7000 th Epoch Train AUC: 0.5906 Loss: 0.8339\n",
      "7100 th Epoch Train AUC: 0.5910 Loss: 0.8334\n",
      "7200 th Epoch Train AUC: 0.5910 Loss: 0.8330\n",
      "7300 th Epoch Train AUC: 0.5911 Loss: 0.8326\n",
      "7400 th Epoch Train AUC: 0.5912 Loss: 0.8323\n",
      "7500 th Epoch Train AUC: 0.5912 Loss: 0.8319\n",
      "7600 th Epoch Train AUC: 0.5912 Loss: 0.8316\n",
      "7700 th Epoch Train AUC: 0.5912 Loss: 0.8312\n",
      "7800 th Epoch Train AUC: 0.5912 Loss: 0.8309\n",
      "7900 th Epoch Train AUC: 0.5913 Loss: 0.8305\n",
      "8000 th Epoch Train AUC: 0.5913 Loss: 0.8302\n",
      "8100 th Epoch Train AUC: 0.5914 Loss: 0.8298\n",
      "8200 th Epoch Train AUC: 0.5914 Loss: 0.8295\n",
      "8300 th Epoch Train AUC: 0.5914 Loss: 0.8291\n",
      "8400 th Epoch Train AUC: 0.5914 Loss: 0.8288\n",
      "8500 th Epoch Train AUC: 0.5914 Loss: 0.8284\n",
      "8600 th Epoch Train AUC: 0.5914 Loss: 0.8281\n",
      "8700 th Epoch Train AUC: 0.5914 Loss: 0.8278\n",
      "8800 th Epoch Train AUC: 0.5914 Loss: 0.8274\n",
      "8900 th Epoch Train AUC: 0.5915 Loss: 0.8271\n",
      "9000 th Epoch Train AUC: 0.5915 Loss: 0.8267\n",
      "9100 th Epoch Train AUC: 0.5916 Loss: 0.8264\n",
      "9200 th Epoch Train AUC: 0.5916 Loss: 0.8260\n",
      "9300 th Epoch Train AUC: 0.5916 Loss: 0.8257\n",
      "9400 th Epoch Train AUC: 0.5916 Loss: 0.8254\n",
      "9500 th Epoch Train AUC: 0.5916 Loss: 0.8250\n",
      "9600 th Epoch Train AUC: 0.5916 Loss: 0.8247\n",
      "9700 th Epoch Train AUC: 0.5917 Loss: 0.8243\n",
      "9800 th Epoch Train AUC: 0.5920 Loss: 0.8239\n",
      "9900 th Epoch Train AUC: 0.5920 Loss: 0.8236\n",
      "10000 th Epoch Train AUC: 0.5920 Loss: 0.8233\n",
      "10100 th Epoch Train AUC: 0.5920 Loss: 0.8229\n",
      "10200 th Epoch Train AUC: 0.5921 Loss: 0.8226\n",
      "10300 th Epoch Train AUC: 0.5921 Loss: 0.8222\n",
      "10400 th Epoch Train AUC: 0.5921 Loss: 0.8219\n",
      "10500 th Epoch Train AUC: 0.5921 Loss: 0.8216\n",
      "10600 th Epoch Train AUC: 0.5922 Loss: 0.8212\n",
      "10700 th Epoch Train AUC: 0.5922 Loss: 0.8209\n",
      "10800 th Epoch Train AUC: 0.5923 Loss: 0.8205\n",
      "10900 th Epoch Train AUC: 0.5923 Loss: 0.8202\n",
      "11000 th Epoch Train AUC: 0.5923 Loss: 0.8199\n",
      "11100 th Epoch Train AUC: 0.5923 Loss: 0.8195\n",
      "11200 th Epoch Train AUC: 0.5923 Loss: 0.8192\n",
      "11300 th Epoch Train AUC: 0.5923 Loss: 0.8189\n",
      "11400 th Epoch Train AUC: 0.5923 Loss: 0.8186\n",
      "11500 th Epoch Train AUC: 0.5923 Loss: 0.8183\n",
      "11600 th Epoch Train AUC: 0.5923 Loss: 0.8180\n",
      "11700 th Epoch Train AUC: 0.5923 Loss: 0.8176\n",
      "11800 th Epoch Train AUC: 0.5923 Loss: 0.8173\n",
      "11900 th Epoch Train AUC: 0.5923 Loss: 0.8170\n",
      "12000 th Epoch Train AUC: 0.5923 Loss: 0.8167\n",
      "12100 th Epoch Train AUC: 0.5923 Loss: 0.8164\n",
      "12200 th Epoch Train AUC: 0.5923 Loss: 0.8161\n",
      "12300 th Epoch Train AUC: 0.5923 Loss: 0.8158\n",
      "12400 th Epoch Train AUC: 0.5923 Loss: 0.8154\n",
      "12500 th Epoch Train AUC: 0.5923 Loss: 0.8151\n",
      "12600 th Epoch Train AUC: 0.5923 Loss: 0.8148\n",
      "12700 th Epoch Train AUC: 0.5923 Loss: 0.8145\n",
      "12800 th Epoch Train AUC: 0.5923 Loss: 0.8142\n",
      "12900 th Epoch Train AUC: 0.5923 Loss: 0.8139\n",
      "13000 th Epoch Train AUC: 0.5924 Loss: 0.8136\n",
      "13100 th Epoch Train AUC: 0.5924 Loss: 0.8133\n",
      "13200 th Epoch Train AUC: 0.5924 Loss: 0.8129\n",
      "13300 th Epoch Train AUC: 0.5925 Loss: 0.8126\n",
      "13400 th Epoch Train AUC: 0.5926 Loss: 0.8122\n",
      "13500 th Epoch Train AUC: 0.5927 Loss: 0.8119\n",
      "13600 th Epoch Train AUC: 0.5928 Loss: 0.8116\n",
      "13700 th Epoch Train AUC: 0.5928 Loss: 0.8112\n",
      "13800 th Epoch Train AUC: 0.5929 Loss: 0.8109\n",
      "13900 th Epoch Train AUC: 0.5929 Loss: 0.8106\n",
      "14000 th Epoch Train AUC: 0.5929 Loss: 0.8103\n",
      "14100 th Epoch Train AUC: 0.5929 Loss: 0.8100\n",
      "14200 th Epoch Train AUC: 0.5929 Loss: 0.8097\n",
      "14300 th Epoch Train AUC: 0.5930 Loss: 0.8094\n",
      "14400 th Epoch Train AUC: 0.5930 Loss: 0.8091\n",
      "14500 th Epoch Train AUC: 0.5930 Loss: 0.8088\n",
      "14600 th Epoch Train AUC: 0.5931 Loss: 0.8084\n",
      "14700 th Epoch Train AUC: 0.5932 Loss: 0.8081\n",
      "14800 th Epoch Train AUC: 0.5933 Loss: 0.8078\n",
      "14900 th Epoch Train AUC: 0.5935 Loss: 0.8074\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[ 0.08147664, -0.03042177, -0.0400863 ,  0.09311056,  0.13341278],\n       [-0.03723866, -0.1469928 ,  0.07704131, -0.04528763, -0.01072775],\n       [ 0.08747406,  0.06737929,  0.10285426,  0.03216217, -0.04981566],\n       ...,\n       [-0.00807297, -0.03849746,  0.01556597,  0.09482423,  0.09166291],\n       [ 0.00284889, -0.0739996 ,  0.03634903, -0.13460866,  0.14565124],\n       [-0.10592775, -0.00781822, -0.07368542,  0.1743885 ,  0.12530404]]) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 305\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    306\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3606\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3695\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[1;32m-> 3696\u001b[1;33m                       (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   3697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1165\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \"\"\"\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    308\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    310\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument array([[ 0.08147664, -0.03042177, -0.0400863 ,  0.09311056,  0.13341278],\n       [-0.03723866, -0.1469928 ,  0.07704131, -0.04528763, -0.01072775],\n       [ 0.08747406,  0.06737929,  0.10285426,  0.03216217, -0.04981566],\n       ...,\n       [-0.00807297, -0.03849746,  0.01556597,  0.09482423,  0.09166291],\n       [ 0.00284889, -0.0739996 ,  0.03634903, -0.13460866,  0.14565124],\n       [-0.10592775, -0.00781822, -0.07368542,  0.1743885 ,  0.12530404]]) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##restored session\n",
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph(model_name)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    new_saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(n_epochs):\n",
    "        _, iloss, y_hat, temp_train_acc = sess.run([train_step, loss, prediction, accuracy], {X_hold:data_x, Y_hold:data_y,keep_prob : 1.0})\n",
    "        temp_test_acc = sess.run(accuracy, feed_dict={X_hold:X_test, Y_hold:test_y,keep_prob : 1.0}) \n",
    "        if i%100==0:\n",
    "            train_acc.append(temp_train_acc)\n",
    "            test_acc.append(temp_test_acc)\n",
    "            losses.append(iloss)\n",
    "            aucs.append(roc_auc_score(data_y, y_hat))\n",
    "        if i%100==0:\n",
    "            print('%i th Epoch Train AUC: %.4f Loss: %.4f' % (i, roc_auc_score(data_y, y_hat), iloss))\n",
    "    \n",
    "    multi_prob_predictions = sess.run(z2, feed_dict={X_hold:X_test, keep_prob : 1.0})\n",
    "    W1_matrix = sess.run(W1)\n",
    "    W2_matrix = sess.run(W2)\n",
    "    b1_vector = sess.run(b1)\n",
    "    b2_vector = sess.run(b2)\n",
    "    saver.save(sess, 'MLP_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 312  756]\n",
      " [ 201 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.29      0.39      1068\n",
      "         1.0       0.60      0.85      0.70      1319\n",
      "\n",
      "    accuracy                           0.60      2387\n",
      "   macro avg       0.60      0.57      0.55      2387\n",
      "weighted avg       0.60      0.60      0.56      2387\n",
      "\n",
      "Validation ROC-AUC score: 0.5698733293012241\n",
      "Validation AUC score:     0.5698733293012241\n",
      "Accuracy: 59.91%\n"
     ]
    }
   ],
   "source": [
    "tensor_predictions = predictor(multi_prob_predictions)\n",
    "metrics_classific(y_test,tensor_predictions, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1),(ax2)) = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True)\n",
    "        \n",
    "# ax1.plot(range(n_epochs//100), losses)\n",
    "ax1.title.set_text('Loss') \n",
    "        \n",
    "# accuracy\n",
    "ax2.plot(train_acc, 'b-', label='train accuracy')\n",
    "ax2.plot(test_acc, 'k-', label='test accuracy')\n",
    "ax2.title.set_text('Train and Test Accuracy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "W1 = pd.read_csv('W1_matrix.csv',header=None).values\n",
    "W2 = pd.read_csv('W2_matrix.csv',header=None).values\n",
    "b1 = pd.read_csv('b1_vector.csv',header=None).values\n",
    "b2 = pd.read_csv('b2_vector.csv',header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09992941],\n",
       "       [0.1003964 ],\n",
       "       [0.10005996],\n",
       "       [0.0998529 ],\n",
       "       [0.09993495]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_function(X_test,W,b):\n",
    "    val_predict = np.dot(np.array(X_test),W)\n",
    "    new_val_predict = np.zeros(shape=(val_predict.shape))\n",
    "    for i in range(len(val_predict)):\n",
    "        for j in range(len(b)):\n",
    "            new_val_predict[i] = [val_predict[i][j]+b[j] for j in range(len(b))]\n",
    "    return new_val_predict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = Z_function(X_test,W1,b1)\n",
    "#LeakyRelu\n",
    "a1 = np.where(z1 > 0, z1, z1 * 0.01)\n",
    "# Relu\n",
    "a_relu = np.maximum(0, z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2387, 5), (2387, 5))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape, a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-485.16626698, -683.16955633, 1230.55196917, -254.74889505,\n",
       "        853.69844944])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -4.85166267,   -6.83169556, 1230.55196917,   -2.54748895,\n",
       "        853.69844944])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LeakyRelu\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        , 1230.55196917,    0.        ,\n",
       "        853.69844944])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Relu\n",
    "a_relu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = Z_function(a_relu,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2387, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-188.55547915,  -73.16680937])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "valudate_prediction = predictor(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valudate_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 301  767]\n",
      " [ 213 1106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.28      0.38      1068\n",
      "         1.0       0.59      0.84      0.69      1319\n",
      "\n",
      "    accuracy                           0.59      2387\n",
      "   macro avg       0.59      0.56      0.54      2387\n",
      "weighted avg       0.59      0.59      0.55      2387\n",
      "\n",
      "Validation ROC-AUC score: 0.5601746158848067\n",
      "Validation AUC score:     0.5601746158848067\n",
      "Accuracy: 58.94%\n",
      "LogLoss : 2.712948309096176\n"
     ]
    }
   ],
   "source": [
    "metrics_classific(y_test,valudate_prediction, X_test)\n",
    "print(\"LogLoss :\", log_loss(y_test,sigmoid(z2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = Z_function(X_validate,W1,b1)\n",
    "a1 = np.where(z1 > 0, z1, z1 * 0.01) #LeakyRelu\n",
    "#a1 = np.maximum(0, z1) #Relu\n",
    "z2 = Z_function(a1,W2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[162 373]\n",
      " [ 98 544]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.30      0.41       535\n",
      "         1.0       0.59      0.85      0.70       642\n",
      "\n",
      "    accuracy                           0.60      1177\n",
      "   macro avg       0.61      0.58      0.55      1177\n",
      "weighted avg       0.61      0.60      0.57      1177\n",
      "\n",
      "Validation ROC-AUC score: 0.5750778816199378\n",
      "Validation AUC score:     0.5750778816199378\n",
      "Accuracy: 59.98%\n",
      "LogLoss : 2.929621206215363\n"
     ]
    }
   ],
   "source": [
    "metrics_classific(y_validate,predictor(z2), X_validate)\n",
    "print(\"LogLoss :\", log_loss(y_validate,sigmoid(z2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
